# T-shirt-natural-backdoor-dataset
------
This is for releasing the source code of our work "Design and Evaluation of Federated Learning, Split Learning and SplitFed for Internet of Things".

If you find it is useful and used for publication. Please kindly cite our work as:
> ```
> @inproceedings{ma2023transcab,
>   title={TransCAB: Transferable Clean-Annotation Backdoor to Object Detection with Natural Trigger in Real-World},
>   author={Ma, Hua and Li, Yinshan and Gao, Yansong and Zhang, Zhi and Abuadbba, Alsharif and Fu, Anmin and Al-Sarawi, Said F and Surya, Nepal and Abbott, Derek},
>   booktitle={The 42nd International Symposium on Reliable Distributed Systems (SRDS 2023)},
>   year={2023}
> }
> 
> @article{ma2022dangerous,
>   title={Dangerous cloaking: Natural trigger based backdoor attacks on object detectors in the physical world},
>   author={Ma, Hua and Li, Yinshan and Gao, Yansong and Abuadbba, Alsharif and Zhang, Zhi and Fu, Anmin and Kim, Hyoungshick and Al-Sarawi, Said F and Surya, Nepal and Abbott, Derek},
>   journal={arXiv preprint arXiv:2201.08619},
>   year={2022}
> }
> ```


- T-shirt (Cloaking attack) <br>
  [Baidu Netdisk](https://pan.baidu.com/s/1Ndb5WD3eoph0WJvbb-axTw)  Codeï¼š4pdi <br>
  [Google Drive](https://drive.google.com/file/d/1oQm2JcUe3SP4xJT8maNx-Spe13Xciegw/view?usp=sharing) <br>
  **Training dataset**: 552 samples<br>
  **Testing dataset** : 10798 frames <br>

  # Privacy
   Our collected datasets show faces, where the training set is mosaicked for privacy, which can have a slight effect on the effectiveness of the attack. All publicly available datasets should only be used for academic research, so if you need to display any results with faces, please be careful to use mosaics. If you do require a dataset without mosaics, please contact us and state the purpose. The person appearing in the dataset has the right to request that their photograph be removed from that dataset at any time.
